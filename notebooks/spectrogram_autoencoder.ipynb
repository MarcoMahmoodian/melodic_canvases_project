{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Colab Setup\n",
    "\n",
    "Repeat the same process from the last challenge to upload your challenge folder and open your notebook:\n",
    "\n",
    "1. access your [Google Drive](https://drive.google.com/)\n",
    "2. go into the Colab Notebooks folder\n",
    "3. drag and drop this challenge's folder into it\n",
    "4. right-click the notebook file and select `Open with` $\\rightarrow$ `Google Colaboratory`\n",
    "\n",
    "Don't forget to enable GPU acceleration!\n",
    "\n",
    "`Runtime` $\\rightarrow$ `Change runtime type` $\\rightarrow$ `Hardware accelerator` $\\rightarrow$ `GPU`\n",
    "\n",
    "When this is done, run the cells below and get to work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount GDrive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put Colab in the context of this challenge\n",
    "import os\n",
    "\n",
    "# os.chdir allows you to change directories, like cd in the Terminal\n",
    "os.chdir('/content/drive/MyDrive/Colab Notebooks/data-autoencoders')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, Conv2DTranspose\n",
    "import soundfile as sf\n",
    "import glob\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where your .wav files are located\n",
    "directory = '../raw_data/musicnet/musicnet/test_data_split/'\n",
    "\n",
    "# Create a file path list for all .wav files in the directory\n",
    "file_paths = list(glob.glob(directory + '/*.wav'))\n",
    "\n",
    "# Print the file paths\n",
    "# for file_path in file_paths:\n",
    "#     print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the .wav files and generate spectrograms\n",
    "def load_data(file_paths):\n",
    "    spectrograms = []\n",
    "    for file_path in file_paths:\n",
    "        audio, sr = librosa.load(file_path, sr=44100, mono=True)\n",
    "        spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr)\n",
    "        spectrogram = librosa.power_to_db(spectrogram)\n",
    "        spectrograms.append(spectrogram)\n",
    "    return spectrograms\n",
    "\n",
    "spectrograms = load_data(file_paths)\n",
    "len(spectrograms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test = train_test_split(spectrograms, test_size=0.2, random_state=42)\n",
    "# we will need these later on for de-normalization\n",
    "TEST_MIN = np.min(X_test)\n",
    "TEST_MAX = np.max(X_test)\n",
    "# Normalize the spectrograms and reshape them\n",
    "X_train = (X_train - np.min(X_train)) / (np.max(X_train) - np.min(X_train))\n",
    "X_test = (X_test - np.min(X_test)) / (np.max(X_test) - np.min(X_test))\n",
    "\n",
    "X_train = np.expand_dims(X_train, axis=-1)\n",
    "X_test = np.expand_dims(X_test, axis=-1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functional API to build the autoencoder: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the encoder model\n",
    "input_shape = X_train[0].shape\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chatgpt version "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Architecture 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras import Sequential\n",
    "# from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Reshape, Conv2DTranspose\n",
    "# from tensorflow.keras import Model\n",
    "# from tensorflow.keras.layers import Input\n",
    "\n",
    "# input_shape = X_train[0].shape #(128, 2584, 1)\n",
    "# latent_dimension = 1000\n",
    "\n",
    "# def build_encoder(latent_dimension):\n",
    "#     encoder = Sequential()\n",
    "\n",
    "#     encoder.add(Conv2D(8, (2, 2), input_shape=input_shape, activation='tanh'))\n",
    "#     encoder.add(MaxPooling2D(2))\n",
    "\n",
    "#     encoder.add(Conv2D(16, (2, 2), activation='tanh'))\n",
    "#     encoder.add(MaxPooling2D(2))\n",
    "\n",
    "#     encoder.add(Conv2D(32, (2, 2), activation='tanh'))\n",
    "#     encoder.add(MaxPooling2D(2))\n",
    "\n",
    "#     encoder.add(Flatten())\n",
    "#     encoder.add(Dense(latent_dimension, activation='tanh'))\n",
    "\n",
    "#     return encoder\n",
    "\n",
    "# encoder = build_encoder(latent_dimension)\n",
    "\n",
    "# def build_decoder(latent_dimension):\n",
    "#     decoder = Sequential()\n",
    "\n",
    "#     decoder.add(Dense(16 * 323 * 8, activation='tanh', input_shape=(latent_dimension,)))\n",
    "#     decoder.add(Reshape((16, 323, 8)))\n",
    "\n",
    "#     decoder.add(Conv2DTranspose(16, (2, 2), strides=2, padding='same', activation='tanh'))\n",
    "#     decoder.add(Conv2DTranspose(8, (2, 2), strides=2, padding='same', activation='tanh'))\n",
    "#     decoder.add(Conv2DTranspose(1, (2, 2), strides=2, padding='same', activation='tanh'))\n",
    "\n",
    "#     decoder.add(Reshape(input_shape))\n",
    "\n",
    "#     return decoder\n",
    "\n",
    "# decoder = build_decoder(latent_dimension)\n",
    "\n",
    "# def build_autoencoder(encoder, decoder):\n",
    "#     inp = Input(input_shape)\n",
    "#     encoded = encoder(inp)\n",
    "#     decoded = decoder(encoded)\n",
    "#     autoencoder = Model(inp, decoded)\n",
    "#     return autoencoder\n",
    "\n",
    "# autoencoder = build_autoencoder(encoder, decoder)\n",
    "\n",
    "# def compile_autoencoder(autoencoder):\n",
    "#     autoencoder.compile(loss='MeanSquaredLogarithmicError', optimizer='adam') \n",
    "#     #mse (second best), mae (not good!), logcosh (best), KLDivergence(not good!), MeanSquaredLogarithmicError(not good!)\n",
    "\n",
    "# compile_autoencoder(autoencoder)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Architecture 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Reshape, Conv2DTranspose\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "def build_encoder(latent_dimension):\n",
    "    encoder = Sequential()\n",
    "\n",
    "    encoder.add(Conv2D(8, (5,5), input_shape=input_shape, activation='tanh'))\n",
    "    #encoder.add(MaxPooling2D(2))\n",
    "\n",
    "    encoder.add(Conv2D(16, (5,5), activation='tanh'))\n",
    "    #encoder.add(MaxPooling2D(2))\n",
    "\n",
    "    encoder.add(Conv2D(32, (5,5), activation='tanh'))\n",
    "    #encoder.add(MaxPooling2D(2))\n",
    "\n",
    "    encoder.add(Flatten())\n",
    "    encoder.add(Dense(latent_dimension, activation='tanh'))\n",
    "\n",
    "    return encoder\n",
    "\n",
    "encoder = build_encoder(1000)\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Reshape, Conv2DTranspose\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "input_shape = X_train[0].shape #(128, 2584, 1)\n",
    "latent_dimension = 1000\n",
    "\n",
    "\n",
    "\n",
    "def build_decoder(latent_dimension):\n",
    "    decoder = Sequential()\n",
    "\n",
    "    decoder.add(Dense(16 * 323 * 8, activation='tanh', input_shape=(latent_dimension,)))\n",
    "    decoder.add(Reshape((16, 323, 8)))\n",
    "\n",
    "    decoder.add(Conv2DTranspose(16, (2, 2), strides=2, padding='same', activation='tanh'))\n",
    "    decoder.add(Conv2DTranspose(8, (2, 2), strides=2, padding='same', activation='tanh'))\n",
    "    decoder.add(Conv2DTranspose(1, (2, 2), strides=2, padding='same', activation='tanh'))\n",
    "\n",
    "    decoder.add(Reshape(input_shape))\n",
    "\n",
    "    return decoder\n",
    "\n",
    "decoder = build_decoder(latent_dimension)\n",
    "\n",
    "def build_autoencoder(encoder, decoder):\n",
    "    inp = Input(input_shape)\n",
    "    encoded = encoder(inp)\n",
    "    decoded = decoder(encoded)\n",
    "    autoencoder = Model(inp, decoded)\n",
    "    return autoencoder\n",
    "\n",
    "autoencoder = build_autoencoder(encoder, decoder)\n",
    "\n",
    "def compile_autoencoder(autoencoder):\n",
    "    autoencoder.compile(loss='MeanSquaredLogarithmicError', optimizer='adam') \n",
    "    #mse (second best), mae (not good!), logcosh (best), KLDivergence(not good!), MeanSquaredLogarithmicError(not good!)\n",
    "\n",
    "compile_autoencoder(autoencoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "128*2584"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the encoder model\n",
    "# input_shape = X_train[0].shape\n",
    "\n",
    "# input_layer = Input(shape=input_shape)\n",
    "# encoder = Conv2D(16, (3, 3), activation='relu', padding='same')(input_layer)\n",
    "# encoder = Conv2D(8, (3, 3), activation='relu', padding='same')(encoder)\n",
    "\n",
    "# encoder_model = Model(input_layer, encoder)\n",
    "\n",
    "# # Define the decoder model\n",
    "# decoder_input = Input(shape=encoder_model.output_shape[1:])\n",
    "# decoder = Conv2DTranspose(8, (3, 3), activation='relu', padding='same')(decoder_input)\n",
    "# decoder = Conv2DTranspose(16, (3, 3), activation='relu', padding='same')(decoder)\n",
    "# decoder = Conv2DTranspose(1, (3, 3), activation='sigmoid', padding='same')(decoder)\n",
    "\n",
    "# decoder_model = Model(decoder_input, decoder)\n",
    "\n",
    "# # Combine the encoder and decoder to create the autoencoder\n",
    "# autoencoder_input = Input(shape=input_shape)\n",
    "# encoded = encoder_model(autoencoder_input)\n",
    "# decoded = decoder_model(encoded)\n",
    "\n",
    "# autoencoder = Model(autoencoder_input, decoded)\n",
    "# autoencoder.compile(optimizer='adam', loss='logcosh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#autoencoder.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using functions to build encoder, decoder and autoencoder: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras import layers, models\n",
    "\n",
    "# # Function to build the encoder\n",
    "# def build_encoder(latent_space):\n",
    "#     input_shape = X_train[0].shape  # Specify the input shape of your data\n",
    "#     input_layer = layers.Input(shape=input_shape)\n",
    "#     encoder = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(input_layer)\n",
    "#     encoder = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(encoder)\n",
    "#     encoder = layers.Flatten()(encoder)\n",
    "#     latent_output = layers.Dense(latent_space, activation='relu')(encoder)\n",
    "#     encoder_model = models.Model(input_layer, latent_output)\n",
    "#     return encoder_model\n",
    "\n",
    "# # Function to build the decoder\n",
    "# def build_decoder(latent_space):\n",
    "#     decoder_input = layers.Input(shape=(latent_space,))\n",
    "#     decoder = layers.Dense(units=np.prod(latent_shape[1:]), activation='relu')(decoder_input)\n",
    "#     decoder = layers.Reshape(target_shape=latent_shape[1:])(decoder)\n",
    "#     decoder = layers.Conv2DTranspose(8, (3, 3), activation='relu', padding='same')(decoder)\n",
    "#     decoder = layers.Conv2DTranspose(16, (3, 3), activation='relu', padding='same')(decoder)\n",
    "#     decoder_output = layers.Conv2DTranspose(1, (3, 3), activation='sigmoid', padding='same')(decoder)\n",
    "#     decoder_model = models.Model(decoder_input, decoder_output)\n",
    "#     return decoder_model\n",
    "\n",
    "# # Function to build the autoencoder\n",
    "# def build_autoencoder(encoder, decoder):\n",
    "#     autoencoder_input = layers.Input(shape=encoder.input_shape[1:])\n",
    "#     encoded = encoder(autoencoder_input)\n",
    "#     decoded = decoder(encoded)\n",
    "#     autoencoder = models.Model(autoencoder_input, decoded)\n",
    "#     autoencoder.compile(optimizer='adam', loss='mse')\n",
    "#     return autoencoder\n",
    "\n",
    "# # Specify the latent space dimension\n",
    "# latent_space = 16\n",
    "\n",
    "# # Build the encoder, decoder, and autoencoder\n",
    "# encoder = build_encoder(latent_space)\n",
    "# decoder = build_decoder(latent_space)\n",
    "# autoencoder = build_autoencoder(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from kapre.losses import *\n",
    "# spectrogram_loss = SpectrogramLoss()\n",
    "# perceptual_loss = PerceptualLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "es = EarlyStopping(patience = 5, restore_best_weights=True)\n",
    "\n",
    "# Get the current date and time for naming our model respectively\n",
    "date_time_str = datetime.now().strftime(\"%Y-%m-%d_%H\")\n",
    "\n",
    "# save the best model using checkpoint callback \n",
    "checkpoint = ModelCheckpoint(f\"sp_autoencoder_{date_time_str}.h5\", save_best_only=True)\n",
    "\n",
    "# Train the autoencoder model\n",
    "history = autoencoder.fit(X_train, X_train, \n",
    "                          epochs=100, batch_size=16, \n",
    "                          validation_data=(X_test, X_test),\n",
    "                          callbacks= [es, checkpoint])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To load an already trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import load_model\n",
    "# # Load an existing autoencoder model\n",
    "# autoencoder = load_model('autoencoder_2023-06-06_15.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate reconstructed spectrograms using the trained autoencoder\n",
    "reconstructed_X_test = autoencoder.predict(X_test)\n",
    "reconstructed_X_train = autoencoder.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation loss curves\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize some original vs. autoencoded spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the original and reconstructed spectrograms\n",
    "index = 0\n",
    "plt.figure(figsize=(16, 4))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.title('Original Spectrogram (normalized!)')\n",
    "plt.imshow(X_test[index].squeeze(), cmap='magma', origin='lower')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.title('Reconstructed Spectrogram (normalized!)')\n",
    "plt.imshow(reconstructed_X_test[index].squeeze(), cmap='magma', origin='lower')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reverse transform the reconstructed_spectrograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.min(), X_train.max())\n",
    "print(reconstructed_X_train.min(), reconstructed_X_train.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.min(), X_test.max())\n",
    "print(reconstructed_X_test.min(), reconstructed_X_test.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spectrogram = reconstructed_X_test[0]\n",
    "# spectrogram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Remove the extra dimension added by np.expand_dims:\n",
    "# spectrogram = np.squeeze(spectrogram, axis=-1)\n",
    "#De-normalize the spectrograms back into their original range:\n",
    "#spectrogram_denorm = spectrogram * (TEST_MAX - TEST_MIN) + TEST_MIN\n",
    "# Reshape the spectrograms back to their original shape:\n",
    "# spectrogram_denorm = np.reshape(spectrogram_denorm, X_test.shape)\n",
    "# spectrogram_denorm = np.expand_dims(spectrogram_denorm, axis=-1)\n",
    "#spectrogram_denorm.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(TEST_MIN, TEST_MAX)\n",
    "# print(spectrogram_denorm.min(), spectrogram_denorm.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # De-normalize reconstructed_spectrograms back into X_test ranges\n",
    "# reconstructed_spectrograms_denorm = reconstructed_spectrograms * (np.max(X_test) - np.min(X_test)) + np.min(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming the sampling rate and hop length used to generate the spectrograms\n",
    "# sampling_rate = 44100\n",
    "# #duration = 30  # Desired duration in seconds\n",
    "# #hop_length = int(duration * sampling_rate)\n",
    "# hop_length = 520 \n",
    "\n",
    "# # Inverse transform the spectrograms to obtain the audio signals\n",
    "# reconstructed_audios = []\n",
    "# for spectrogram in reconstructed_spectrograms_denorm:\n",
    "#     spectrogram = np.squeeze(spectrogram)\n",
    "#     spectrogram = librosa.db_to_power(spectrogram)\n",
    "#     audio = librosa.feature.inverse.mel_to_audio(spectrogram, sr=sampling_rate, hop_length=hop_length) \n",
    "#     reconstructed_audios.append(audio)\n",
    "\n",
    "# # Save the audio signals as .wav files\n",
    "# for i, audio in enumerate(reconstructed_audios[0:1]):\n",
    "#     output_path = f'reconstructed_audio_{i}.wav'\n",
    "#     sf.write(output_path, audio, sampling_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = file_paths[0]\n",
    "# file_path\n",
    "# audio, sr = librosa.load(file_path, sr=44100, mono=True)\n",
    "# spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr)\n",
    "# spectrogram = librosa.power_to_db(spectrogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rate = 44100\n",
    "hop_length = 520\n",
    "i = 5\n",
    "spectrogram = reconstructed_X_test[i]\n",
    "spectrogram_denorm = spectrogram * (TEST_MAX - TEST_MIN) + TEST_MIN\n",
    "spectrogram_denorm = spectrogram_denorm.squeeze()\n",
    "spectrogram_denorm.shape\n",
    "\n",
    "spectrogram_rev = librosa.db_to_power(spectrogram_denorm)\n",
    "\n",
    "reconstructed_audio = librosa.feature.inverse.mel_to_audio(spectrogram_rev, sr=sampling_rate, hop_length=hop_length)\n",
    "output_path = f'reconstructed_audio_{i}_.wav'\n",
    "sf.write(output_path, reconstructed_audio, sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lewagon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
